{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "***\n",
    "** Algorithmes d'optimisation -- L3 MINT et doubles licences 2017/2018 -- Université Paris-Sud **\n",
    "***\n",
    "\n",
    "$\\newcommand{\\Rsp}{\\mathbb{R}}\n",
    "\\newcommand{\\nr}[1]{\\|#1\\|}\n",
    "\\newcommand{\\abs}[1]{|#1|}\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\newcommand{\\sca}[2]{\\langle#1|#2\\rangle}\n",
    "\\newcommand{\\D}{\\mathrm{D}}\n",
    "\\newcommand{\\hdots}{\\dots}\n",
    "\\newcommand{\\cond}{\\mathrm{cond}}$\n",
    "\n",
    "On commence par importer quelques fonctions des TP précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# la commande suivante agrandit les figures\n",
    "plt.rcParams['figure.figsize'] = [9.,6.]\n",
    "\n",
    "def backtrack(f,x,d,m,alpha=0.3,beta=0.5):\n",
    "    t = 1\n",
    "    while f(x+t*d) > f(x) + alpha*t*m:\n",
    "        t = beta*t\n",
    "    return t\n",
    "\n",
    "def gradient_backtracking(f,g,x0,err=1e-6,maxiter=500):\n",
    "    x = x0.copy()\n",
    "    fiter = []\n",
    "    giter = []\n",
    "    k = 0 # nombre d'itérations\n",
    "    while(True): \n",
    "        k = k+1\n",
    "        if k > maxiter: # maximum de 10^6 itérations\n",
    "            print('erreur: nombre maximum d\\'itérations atteint')\n",
    "            break\n",
    "        d = -g(x)\n",
    "        fiter.append(f(x))\n",
    "        giter.append(np.linalg.norm(d))\n",
    "        if np.linalg.norm(d) <= err:\n",
    "            break\n",
    "        t = backtrack(f,x,d,-np.linalg.norm(d)**2)\n",
    "        #if k%10==0: # on affiche des informations toute les 20 itérations\n",
    "        #    print('iteration %d: f=%f, |g|=%f, step=%f' % (k, f(x), np.linalg.norm(d),t))\n",
    "        x = x + t*d\n",
    "    return x,np.array(fiter),np.array(giter)\n",
    "\n",
    "def check_gradient(f,g,x0):\n",
    "    N = len(x0)\n",
    "    gg = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        eps = 1e-4\n",
    "        e = np.zeros(N)\n",
    "        e[i] = eps\n",
    "        gg[i] = (f(x0+e) - f(x0-e))/(2*eps)\n",
    "    print('erreur numerique dans le calcul du gradient: %g (doit etre petit)' % np.linalg.norm(g(x0)-gg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# TP 4: Pénalisation et gradient projeté\n",
    "\n",
    "## Partie I: Problème d'obstacle\n",
    "\n",
    "On considère un système physique constitué d'une chaine de $N+1$ ressorts. Les deux extrémités du $i$ème ressort ($0\\leq i\\leq N$ sont les points $(t_i,x_i) \\in\\Rsp^2$ et $(t_{i+1},x_{i+1}) \\in \\Rsp^2$, où $t_i = hi$ est fixé.  On considère également que la chaine est fixée à ses extrémités: $x_0 = x_{N+1} = 0$. Il reste donc $N$ inconnues $x = (x_1,\\hdots,x_N)\\in \\Rsp^N$. L'énergie du système est donnée par la formule suivante:\n",
    "\n",
    "$$J(x) = J(x_1,\\hdots,x_N) = \\frac{1}{2}\\sum_{0\\leq i\\leq N-1} \\nr{x_{i+1} - x_i}^2 $$ \n",
    "\n",
    "où l'on a donc fixé $x_0 = x_{N+1} = 0$. On pose un obstacle sous la chaîne de ressort, qui force chacune des coordonnées $x_i$ a être minorée par une constante $f_i$ (on peut penser à une main qui pousse le ressort par exemple). On arrive dont au problème d'optimisation\n",
    "\n",
    "$$ \\min_{x\\in K} J(x) \\hbox{ où } K = \\{x\\in \\Rsp^N \\mid \\forall 1\\leq i\\leq N, x_i \\geq f_i \\}. $$\n",
    "\n",
    "Nous allons la résolution numérique de ce problème d'optimisation par la méthode de gradient projeté. On rappelle les formules suivantes, issues du TD:\n",
    "\n",
    "- La projection d'un point $y\\in\\Rsp^d$ sur le convexe fermé $K$ est donnée par \n",
    "\n",
    "$$ p_K(y) = (\\max(y_N,f_N),\\hdots,\\max(y_N,f_N)) $$\n",
    "\n",
    "- On admet que la fonction $J$ peut être mise sous la forme\n",
    "\n",
    "$$ J(x) = \\frac{1}{2} \\sca{x}{Q x}  \\hbox{ où } Q = \\begin{pmatrix}2 & -1  & 0 &\\cdots & 0 \\\\\n",
    "-1 & 2 & -1 & \\ddots & \\vdots   \\\\ \n",
    "0 & \\ddots & \\ddots & \\ddots& \\vdots \\\\\n",
    "\\vdots & \\ddots & -1 & 2 & -1 \\\\\n",
    "0 & \\hdots & 0 & -1 & 2\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Le gradient de la fonction  $J$ en $x\\in \\Rsp^N$ est alors donné par $\\nabla J(x) = Q x.$\n",
    "\n",
    "**Q1)** Écrire une fonction projK(x) retournant la projection de $x\\in \\Rsp^N$ sur $K$ (la tester avec des petites valeurs de $N$). On fixe désormais $N=30$: écrire la matrice $Q$ et deux fonctions $J(x)$ et $gradJ(x)$ calculant la valeur et le gradient de $J$. Vérifier le calcul du gradient avec check_gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2. -1.  0.  0.  0.]\n",
      " [-1.  2. -1.  0.  0.]\n",
      " [ 0. -1.  2. -1.  0.]\n",
      " [ 0.  0. -1.  2. -1.]\n",
      " [ 0.  0.  0. -1.  2.]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projK(x):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "On rappelle que l'algorithme du gradient projeté est défini de la manière suivante:\n",
    "\n",
    "$$ \\begin{cases}\n",
    "x^{(0)} \\in \\Rsp^N\\\\\n",
    "x^{(k+1)} = p_K(x^{(k)} - \\tau \\nabla J(x^{(k)}))\n",
    "\\end{cases} $$\n",
    "\n",
    "où $\\tau>0$. On a démontré en cours que si \n",
    "\n",
    "$$ \\forall x\\in \\Rsp^M, m \\leq \\D^2 J(x) \\leq M, $$\n",
    "\n",
    "alors l'algorithme converge dès que $\\tau < 2m/M^2$, avec un taux optimal lorsque $\\tau^* = m/M^2$.\n",
    "\n",
    "**Q2)** Montrer que $\\D^2 J(x) = Q$; calculer les valeurs propres de $Q$ via la fonction np.linalg.eigvalsh. Quelle valeur de $\\tau^*$ l'estimation ci-dessus donne-t-elle ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <completer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Q3)** Écrire une boucle réalisant l'algorithme du gradient projeté (pour $1\\leq k\\leq 1000$), et stockant le vecteur $G=(\\nr{x^{(k+1)} - x^{(k)}})$ (comme il s'agit d'un algorithme de point fixe, c'est une bonne manière de quantifier la convergence). Tracer la solution $x \\in \\Rsp^N$ trouvée toutes les 20 itérations (on suggère plt.plot(T,x)).  Tester pour $\\tau = \\tau^*$. En pratique, vérifier que l'algorithme converge toujours pour des valeurs de $\\tau$ plus grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <completer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Q4**) Comme $\\nabla J(x) = Q$, l'algorithme peut en fait être décrit par\n",
    "\n",
    "$$ \\begin{cases}\n",
    "x^{(0)} \\in \\Rsp^N\\\\\n",
    "x^{(k+1)} = p_K(A_\\tau x^{(k)}) \n",
    "\\end{cases} $$\n",
    "\n",
    "où $A_\\tau = \\mathrm{Id}_N - \\tau Q$. Montrer que si toutes les valeurs propres de $A_\\tau$ sont de module $<1$, alors l'application $x\\mapsto A_\\tau x$ est contractante. Vérifier numériquement ce critère pour $\\tau=0.5$ (on utilisera np.linalg.eigvalsh pour calculer les valeurs propres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <completer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Q5)** Comparer la méthode du gradient projeté à celle où on pénalise la contrainte: \n",
    "\n",
    "$$P_\\eps := \\min_{x\\in\\Rsp^d} J_\\eps(x) \\hbox{ où } J_\\eps(x) = J(x) + \\frac{1}{\\eps} \\sum_{1\\leq i\\leq N} \\max(F_i - x_i,0)^2. $$\n",
    "\n",
    "Écrire deux fonctions Jeps/gradJeps calculant $J_\\eps/\\nabla J_\\eps$. Vérifier le calcul du gradient en utilisant check_gradient. Résoudre le problème $P_\\eps$ par descente de gradient avec backtracking pour $\\eps=1,0.1,0.01,0.001$. Interpréter l'explosion du nombre d'itérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <completer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Partie II: Projection sur le simplexe, application à l'optimisation de portefeuilles\n",
    "\n",
    "Comme dans le TD, on pose $\\Delta = \\{ x\\in \\Rsp_+^n \\mid \\sum_{1\\leq i \\leq n} x_i = 1\\}$. On cherche à calculer la projection d'un point $y\\in\\Rsp^n$ sur $\\Delta$. Dans le TD, on a pu démontrer le résultat suivant:\n",
    "\n",
    "- il existe $\\kappa\\in\\Rsp$ tel que $\\sum_{1\\leq i\\leq n} \\max(y_i - \\kappa, 0) = 1$\n",
    "- la projection de $y$ sur $\\Delta$ s'écrit alors $p_\\Delta(y) = (\\max(y_i - \\kappa, 0))_{1\\leq i\\leq n}$\n",
    "\n",
    "**Q1)** Soit $y = (0.1,1.5,2.1) \\in \\Rsp^3$. Écrire une fonction $g(\\kappa) := \\sum_{1\\leq i\\leq n} \\max(y_i - \\kappa,0) - 1$ (utiliser np.sum et np.maximum). Trouver $\\kappa$ vérifiant $g(\\kappa) = 1$ en utilisant scipy.optimize.fsolve. \n",
    "\n",
    "**Q2)** En s'inspirant du code de la fonction précédente, écrire une fonction proj_simplexe calculant la projection d'un point $y\\in\\Rsp^n$ sur $\\Delta$. Pour vérifier le bon fonctionnement de cette fonction, fixez $y\\in\\Rsp^3$ et calculer $p=$proj_simplexe(y); vérifier ensuite que \n",
    "\n",
    "$$ \\forall z \\in \\Delta, \\sca{y - p_\\Delta(y)}{p_\\Delta(y) - z} \\geq 0 $$\n",
    "\n",
    "Comme il ne s'agit bien sûr pas de considérer *tous* les points dans le simplexe, on pourra choisir quelques $z$ aléatoires dans $\\Delta$. (dans le cas $n=2$, on peut également tirer quelques points aléatoirement dans le plan et visualiser le segment qui les relie à leur projection sur $\\Delta$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "# <completer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Q3)** Implémenter l'algorithme du gradient projeté pour résoudre le problème (en dimension $n=8$):\n",
    "\n",
    "$$ \\min_{x \\in \\Delta} \\frac{1}{2} \\sca{Q x}{x} + \\frac{1}{2\\eps} (\\sca{r}{x} - \\bar{r})^2 $$\n",
    "\n",
    "où $Q,r,\\bar{r}$ et $\\eps$ sont donnés ci-dessous. (On pourra estimer le paramètre $\\tau$ de l'algorithme du gradient projeté par tâtonnement, ou comme dans la partie précédente.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(8,8)\n",
    "Q = np.eye(8) + 0.1*np.dot(A.T,A)\n",
    "r = np.random.rand(8)\n",
    "rbar = 0.7*np.max(r)  + 0.3*np.min(r)\n",
    "eps = 0.1\n",
    "\n",
    "# on veut trouver la stratégie qui fournit un rendement égal à 70% du rendement du meilleur produit, \n",
    "# tout en minimisant le risque\n",
    "\n",
    "# <completer>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
