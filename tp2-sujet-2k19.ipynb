{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "***\n",
    "**Algorithmes d'optimisation -- L3 MINT et doubles licences -- Université Paris-Sud**\n",
    "***\n",
    "\n",
    "$\\newcommand{\\Rsp}{\\mathbb{R}}\n",
    "\\newcommand{\\nr}[1]{\\|#1\\|}\n",
    "\\newcommand{\\abs}[1]{|#1|}\n",
    "\\newcommand{\\eps}{\\varepsilon}\n",
    "\\newcommand{\\sca}[2]{\\langle#1|#2\\rangle}\n",
    "\\newcommand{\\D}{\\mathrm{D}}\n",
    "\\newcommand{\\hdots}{\\dots}\n",
    "\\newcommand{\\cond}{\\mathrm{cond}}$\n",
    "\n",
    "# TP 2: Régression logistique\n",
    "\n",
    "## Partie I: Descente de gradient avec rebroussement d'Armijo ##\n",
    "\n",
    "Étant donné un point $x^{(k)}$ et une direction de descente $d^{(k)}$ le pas d'Armijo est défini de la manière suivante: \n",
    "\n",
    "$$ t^{(k)}_{\\mathrm{arm}} = \\max \\left\\{ t  \\mid t = \\beta^\\ell, \\ell\\in \\mathbb{N}, \\hbox{ tq } f(x^{(k)} + t d^{(k)}) \\leq f(x) + \\alpha t\\sca{\\nabla f(x)}{d^{(k)}} \\right\\}, $$\n",
    "\n",
    "où on prendra $\\alpha = 0.3, \\beta = 0.5$. Algorithmiquement, on procède de la manière suivante pour calculer $t^{(k)}_{\\mathrm{arm}}$ en fonction de $x=x^{(k)}$ et $v = d^{(k)}$:\n",
    "\n",
    "$$\n",
    "\\left|\n",
    "\\begin{aligned}\n",
    "&\\mathrm{pas\\_armijo}(f,x,v)\\\\\n",
    "&\\qquad t \\gets 1\\\\\n",
    "&\\qquad m \\gets \\sca{\\nabla f(x)}{v}\\\\\n",
    "&\\qquad \\textbf{while } f(x + t v) > f(x) + \\alpha t m \\\\\n",
    "&\\qquad\\qquad t \\gets \\beta t\\\\\n",
    "&\\qquad \\mathrm{return}~t\n",
    "\\end{aligned}\\right.\n",
    "$$\n",
    "\n",
    "L'algorithme de descente de gradient avec rebroussement d'Armijo s'écrit alors de la manière suivante:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "d^{(k)} = - \\nabla f(x^{(k)}) \\\\\n",
    "t^{(k)} = \\mathrm{pas\\_armijo}(f,x^{(k)}, d^{(k)})\\\\\n",
    "x^{(k+1)} = x^{(k)} + t^{(k)} d^{(k)}\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "**QI.1**)  Écrire les fonctions suivantes:\n",
    "- `pas_armijo(f,gradf,x)` prend en entrée $f:\\Rsp^N\\to\\Rsp$, `gradf`$=\\nabla f:\\Rsp^N\\to\\Rsp^N$, $x,d\\in\\Rsp^N$. On choisira `alpha`$=0.3$, `beta`$=0.5$ et on retournera le pas $t$. \n",
    "- `gradient_armijo(f,gradf,x0,err=1e-6,maxiter=1000)` prenant en argument la fonction `f`, `gradf`, `x0`=$x^{(0)}$ et un critère d'arrêt `err`$\\in\\Rsp$, et qui effectue l'algorithme de descente de gradient avec pas d'Armijo en arrêtant la boucle dès que $\\nr{d^{(k)}} \\leq$ `err` où dès que $k\\geq$ `maxiter`. Cette fonction retournera le point $x$ trouvé, un vecteur contenant la suite  $f(x^{(k)})$ et un second vecteur contenant $\\nr{\\nabla f(x^{(k)})}$. Indications:\n",
    "    - **Pour la fonction gradient_armijo, ne pas hésiter à copier-coller gradient_optimal et à faire les modifications nécessaires**\n",
    "    - **Ne stocker que l'itération courante et pas la suite des itérées**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.3\n",
    "beta = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# on importe les modules numpy et pyplot\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# les deux commandes suivante paramètrent l'affichage des figures\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [9.,6.]\n",
    "\n",
    "# les paramètres alpha et beta comportent une valeur par défaut, c'est-à-dire que \n",
    "# pas_armijo(f,x,d,m) est équivalent à pas_armijo(f,x,d,m,0.3,0.5)\n",
    "def pas_armijo(f,gradf,x,v):\n",
    "    t = 1\n",
    "    m = np.dot(gradf(x),v)\n",
    "    #print(f(x+t*v))\n",
    "    #print(\" \")\n",
    "    \n",
    "   # print(m)\n",
    "    \n",
    "    while f(x+t*v)>f(x)+alpha*t*m:\n",
    "        t = beta * t\n",
    "    return t\n",
    "    \n",
    "# la descente de gradient prend en argument:\n",
    "# f = la fonction à évaluer\n",
    "# gradf = le gradient de f\n",
    "# x0 = le point de départ\n",
    "def gradient_armijo(f,gradf,x0,err=1e-6,maxiter=1000):\n",
    "    # ne pas hésiter à copier-coller et adapter gradient_optimal...\n",
    "    x = x0\n",
    "    niter=0\n",
    "    E = []\n",
    "    F = []\n",
    "    \n",
    "    k = 0 # nombre d'itérations\n",
    "    while (True): \n",
    "        k = k+1\n",
    "        if k > 1e6: # maximum de 10^6 itérations\n",
    "            print('erreur: nombre maximum d\\'itérations atteint')\n",
    "            break\n",
    "        # calculer la direction de descente\n",
    "        d = -gradf(x)\n",
    "        F.append(np.linalg.norm(gradf(x)))\n",
    "        E.append(f(x))\n",
    "        # vérifier le critère d'arrêt, et quitter la boucle (avec break) s'il est vérifié\n",
    "        if np.linalg.norm(d) <= err:\n",
    "            break\n",
    "        # calculer le pas de descente et mettre à jour x\n",
    "        t = pas_armijo(f,gradf,x,d)\n",
    "        x = x + t*d\n",
    "    E = np.array(E)\n",
    "    F = np.array(F)\n",
    "    return x,E,F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 + np.exp(x)\n",
    "\n",
    "def gradf(x):\n",
    "    return 2*x + np.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**QI.2**) Tester la fonction `gradient_armijo` en dimension $N=1$, $f(x) = x^{2} + e^{x}$, $x_0 = 1$ et en prenant pour critère d'arrêt `err`$= 10^{-8}$. Vous devriez trouver $x^* = -0.3517...$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.3517337147878348,\n",
       " array([3.71828183, 0.86787462, 0.83305333, 0.82786917, 0.82727049,\n",
       "        0.82719465, 0.82718534, 0.82718419, 0.82718405, 0.82718403,\n",
       "        0.82718403, 0.82718403, 0.82718403, 0.82718403, 0.82718403,\n",
       "        0.82718403, 0.82718403, 0.82718403, 0.82718403]),\n",
       " array([4.71828183e+00, 4.76488159e-01, 1.77144731e-01, 6.09844192e-02,\n",
       "        2.16070941e-02, 7.58025446e-03, 2.66865417e-03, 9.38355303e-04,\n",
       "        3.30088325e-04, 1.16098597e-04, 4.08363587e-05, 1.43634537e-05,\n",
       "        5.05211957e-06, 1.77699969e-06, 6.25030829e-07, 2.19844397e-07,\n",
       "        7.73266876e-08, 2.71984025e-08, 9.56659507e-09]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test de la fonction pas_armijo\n",
    "\n",
    "gradient_armijo(f,gradf,1,err=1e-8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Partie II: Régression logistique avec rebroussement d'Armijo en dimension $N=2$\n",
    "\n",
    "L'explication de la méthode est à lire dans la feuille de TD.\n",
    "On commence par construire les données $(x_a)_{a \\in A} \\subseteq \\Rsp^2$ où :\n",
    "- $A = \\{1,\\hdots,n\\} = A_0\\sqcup A_1$, $A_0 = \\{0, \\hdots, m-1,\\}$, $A_1 = \\{m, 2m-1\\}$, $n = 2m$\n",
    "- Les points $(x_a)_{a\\in A_0}$ sont tirés selon une gaussienne centrée en $(0.5,0.5)$\n",
    "- Les points $(x_a)_{a\\in A_1}$ sont tirés selon une gaussienne centrée en $(-0.5,-0.5)$.\n",
    "\n",
    "On cherche alors à construire, par optimisation de la fonction $F$, un vecteur $w\\in\\Rsp^2$ tel\n",
    "que $\\sigma(\\sca{w}{x_a}) \\simeq 0$ si $a\\in A_0$ et  $\\sigma(\\sca{w}{x_a})\\simeq 1$ si $a\\in A_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = 30\n",
    "n = 2*m\n",
    "X = np.vstack((np.hstack((-0.5+.2*np.random.randn(m,1), -0.5 + .2*np.random.randn(m,1))),\n",
    "               np.hstack((0.5+.2*np.random.randn(m,1), 0.5 + .2*np.random.randn(m,1)))))\n",
    "A0 = range(0,m)\n",
    "A1 = range(m,2*m)\n",
    "plt.plot(X[A0,0],X[A0,1],'.r',label='A0')\n",
    "plt.plot(X[A1,0],X[A1,1],'.g',label='A1')\n",
    "plt.legend()\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**QII.1**: Écrire deux fonctions `F(w,X,A0,A1,gamma)` et `gradF(w,X,A0,A1,\\gamma)` calculant la valeur et le gradient de la fonctionnelle \n",
    "\n",
    "$$ F(w) = - \\left(\\sum_{a\\in A_0} \\log(1-\\sigma(\\sca{w}{x_a})) + \\sum_{a\\in A_1} \\log(\\sigma(\\sca{w}{x_a})\\right) + \\frac{\\gamma}{2} \\nr{w}^2. $$\n",
    "\n",
    "Tester que `gradF` correspond bien au gradient de `F` en utilisant la fonction `verifier_gradient` fournie ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur numérique dans le calcul du gradient: 7.34563e-10 (doit être petit)\n"
     ]
    }
   ],
   "source": [
    "# on définit une fonction sigma(t) correspondant à la sigmoïde\n",
    "def sigma(t):\n",
    "    return np.exp(t)/(1+np.exp(t))\n",
    "\n",
    "def F(w,X,A0,A1,gamma):\n",
    "    rep = 0\n",
    "    #int i = 0\n",
    "    for i in A0:\n",
    "        rep -=np.log(1-sigma(np.dot(w,X[i])))\n",
    "    for i in A1:\n",
    "        rep -= np.log(sigma(np.dot(w,X[i])))\n",
    "        \n",
    "    rep += gamma *0.5*(np.linalg.norm(w)**2)\n",
    "    \n",
    "    return rep\n",
    "    \n",
    "def gradF(w,X,A0,A1,gamma):\n",
    "    rep = 0\n",
    "    for i in A0:\n",
    "        rep += sigma(np.dot(w,X[i])) * X[i]\n",
    "    for i in A1:\n",
    "        rep += (sigma((np.dot(w,X[i]))) -1) * X[i]\n",
    "        \n",
    "    rep += gamma * w\n",
    "    \n",
    "    return rep\n",
    "\n",
    "\"\"\" la fonction verifier_gradient calcule le gradient de f en un point x0 de deux manières:\n",
    "    1) via la fonction gradf donnée en argument \n",
    "    2) via des différences finies: df/de_i (x_0) ~= (f(x_0+eps e_i) - f(x_0))/eps\n",
    "    et compare ces deux résultats: si la fonction gradf est correctement programmée, la différence\n",
    "    entre les deux méthode de calcul devrait être petite \"\"\"\n",
    "def verifier_gradient(f,gradf,x0):\n",
    "    N = len(x0)\n",
    "    gg = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        eps = 1e-5\n",
    "        e = np.zeros(N)\n",
    "        e[i] = eps\n",
    "        gg[i] = (f(x0+e) - f(x0-e))/(2*eps)\n",
    "    print('erreur numérique dans le calcul du gradient: %g (doit être petit)' % np.linalg.norm(gradf(x0)-gg))\n",
    "    \n",
    "# on vérifie l'implémentation de gradF en utilisant la fonction verifier_gradient\n",
    "gamma = .1\n",
    "f = lambda w: F(w,X,A0,A1,gamma)\n",
    "#def f(w):\n",
    "#    return F(w,X,A0,A1,gamma)\n",
    "gradf = lambda w: gradF(w,X,A0,A1,gamma)\n",
    "verifier_gradient(f, gradf, np.random.rand(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**QI.2**: Calculer $w=\\arg\\min_{\\Rsp^2} F$ en utilisant la fonction gradient_armijo. Tracer sur un graphe l'évolution de la norme du gradient au cours des itérations de la descente de gradient, soit $(k,\\nr{\\nabla F(w^{(k)})})$, où l'axe $y$ sera en échelle logarithmique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa5979f96a0>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w0 = np.zeros(2)\n",
    "gamma = 0.01\n",
    "w,giter,fiter = gradient_armijo(f,gradf,w0,err=1e-7,maxiter = 1000)\n",
    "plt.semilogy(giter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**QI.3**: Soit $w$ le minimiseur approché de $F$ calculé dans la question précédente. Tracer sur un graphe:\n",
    "- les points $(x_a)_{a\\in A_0}$ en rouge\n",
    "- les points $(x_a)_{a\\in A_1}$ en bleu\n",
    "- quelques lignes de niveau de la fonction $u:x\\mapsto \\sigma(\\sca{w}{x})$ en utilisant la fonction fournie `afficher_lignes_niveau(w)`.\n",
    "\n",
    "Faire varier le paramètre de régularisation $\\gamma \\in \\{0.01,0.1,1,10\\}$ et observer:\n",
    "- comment varie le nombre d'itérations.\n",
    "- comment varie $\\nr{w}$ (où $\\nr{w}$ est le minimiseur).\n",
    "- quel est l'effet sur la fonction $u:x\\mapsto \\sigma(\\sca{w}{x_i})$.\n",
    "\n",
    "<!--\n",
    "%On peut expliquer le premier point en se rappelant que\n",
    "%Si on note $F_\\gamma$ la fonction avec le paramètre $\\gamma$, montrer que pour $\\gamma' \\geq \\gamma$ on a \n",
    "%$$ \\forall w\\in\\Rsp^d,\\forall v\\in \\Rsp^d, \\sca{D^2 F_\\gamma(w)v}{v} \\leq \\sca{D^2 F_{\\gamma'}(w)v}{v} $$\n",
    "%En déduire que si $m \\leq \\D^2 F_\\gamma \\leq M$ sur $S\\subseteq \\Rsp^d$, alors \n",
    "%$$ m+(\\gamma'-\\gamma) \\leq \\D^2 F_\\gamma \\leq M + \\gamma'-\\gamma $$\n",
    "%, en notant $\\lambda_1(A) < \\hdots \\leq \\lambda_d(A)$ les valeurs propres de $A$,\n",
    "%$$ \\frac{\\lambda_d(A')}{\\lambda_1(A')} \\leq \\frac{\\lambda_d(A)}{\\lambda_1(A)} $$\n",
    "$$\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# on définit une fonction permettant d'afficher les lignes de niveaux de u_w: R^2 -> R\n",
    "# definie par u_w(x) = \\sigma(<x|w>)\n",
    "# NB: u peut être définie en utilisant lambda, par exemple:\n",
    "#    u = lambda (x,y): ... où x,y sont les coordonnées du point\n",
    "def afficher_lignes_niveau(w):\n",
    "    Xcontour,Ycontour = np.meshgrid(np.linspace(-1., 1., 100),\n",
    "                                    np.linspace(-1., 1., 100))\n",
    "    u = lambda x,y: sigma(x*w[0] + y*w[1])\n",
    "    Zcontour = u(Xcontour,Ycontour)\n",
    "    plt.axes([-1.5, -1.5, 1.5, 1.5])\n",
    "    plt.axis('equal')\n",
    "    p = plt.contour(Xcontour, Ycontour, Zcontour, cmap='RdBu')\n",
    "    plt.clabel(p, inline=1, fontsize=10)\n",
    "    \n",
    "# <completer>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Partie III: Régression logistique avec méthode de Newton en dimension $N=2$\n",
    "\n",
    "**QIII.1**: Écrire une fonction `hessF` calculant la hessienne de $F$, en utilisant la formule obtenue en TD. Vérifier le bon fonctionnement de `hessF` via la fonction `verifier_hessienne` fournie ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" cette fonction vérifie numériquement que hessf (=fonction évaluant la hessienne de f) est bien\n",
    "    la dérivée de grad (= fonction évaluant le gradient de f), en un point x0 \"\"\"\n",
    "def verifier_hessienne(gradf,hessf,x0):\n",
    "    N = len(x0)\n",
    "    H = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        eps = 1e-5\n",
    "        e = np.zeros(N)\n",
    "        e[i] = eps\n",
    "        H[i,:] = (gradf(x0+e) - gradf(x0-e))/(2*eps)\n",
    "    print('erreur numerique dans le calcul de la hessienne: %g (doit etre petit)' % np.sum((H-hessf(x0)))**2)\n",
    "    \n",
    "def hessF(w,X,A0,A1,K):\n",
    "    rep = 0\n",
    "    for i in A0:\n",
    "        rep += sigma(np.dot(w,X[i])) * X[i]\n",
    "    for i in A1:\n",
    "        rep += (sigma((np.dot(w,X[i]))) -1) * X[i]\n",
    "        \n",
    "    rep += gamma * w\n",
    "    \n",
    "    return rep\n",
    "    \n",
    "\n",
    "# on vérifie que la hessienne est correcte en utilisant la fonction verifier_hessienne\n",
    "# <completer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**QIII.2**: Écrire une fonction `newton_armijo(f,gradf,hessf,x0,err=1e-6,maxiter=1000)` implémentant la méthode de Newton avec rebroussement d'Armijo, c'est-à-dire l'algorithme suivant:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "g^{(k)} = \\nabla F(x^{(k)}) \\\\\n",
    "d^{(k)} = -[D^2 F(x^{(k)})]^{-1} \\nabla F(x^{(k)}) \\\\\n",
    "t^{(k)} = \\mathrm{pas\\_armijo}(f,x^{(k)},d^{(k)})\\\\\n",
    "x^{(k+1)} = x^{(k)} + t^{(k)} d^{(k)}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Il ne faut pas hésiter à copier-coller la fonction gradient_armijo et à changer ce qui est nécessaire. Pour la résolution du système linéaire, on utilisera `np.linalg.solve`. \n",
    "\n",
    "Utiliser cette fonction pour calculer le minimum de $F$. Comme dans la question Q1.2, tracer la norme du gradient en fonction de l'itération. Vérifier également que le nombre d'itérations dépend peu du choix du paramètre $\\gamma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def newton_armijo(f,gradf,hessf,x0,err=1e-6,maxiter=500):\n",
    "    # la boucle est tres similaire à celle de gradient_armijo: la seule chose qui\n",
    "    # change est le choix de la direction de descente. \n",
    "    # NB: on utilise np.linalg.solve pour résoudre le système linéaire apparaissant dans la méthode\n",
    "    # <completer>\n",
    "\n",
    "\n",
    "# comparer le nombre d'iterations dans la methode de Newton pour gamma dans [0.01,0.1,1,5]\n",
    "# <completer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Partie IV: Application à la classification de caractères manuscrits\n",
    "\n",
    "L'objectif de cette partie est d'appliquer la méthode décrite dans les parties précédentes (où l'on traitait des données en dimension $N=2$) à un jeu de données plus réaliste et de dimension beaucoup plus grande. L'objectif est de distinguer des images de caractères manuscrits. Pour cela, on a demandé à 6000 personnes d'écrire les chiffres de zéro à neuf. Ici, l'on cherchera uniqument à distinguer les chiffres zéro manuscrits des chiffres un. Chaque point de donnée $x_a$ est construit de la manière suivante: \n",
    "\n",
    "- On demande à une personne d'écrire un chiffre (zéro, un, ..., neuf), que l'on stocke sous la forme d'une image en niveaux de gris de taille 28x28 pixels. On représente cette image par une matrice carrée $p_a \\in \\mathcal{M}_{28,28}(\\Rsp)$ (où $(p_{a})_{ij} = 0$ si le pixel $(i,j)$ est noir et $1$ s'il est blanc). \n",
    "- La matrice carrée $p_a \\in \\mathcal{M}_{28,28}(\\Rsp)$ est convertie en un vecteur $x_a\\in\\Rsp^{N}$ de taille $N = 28\\times 28 = 784$. Pour cela, on met bout-à-bout les lignes de la matrice $p$, via la fonction `np.reshape`.\n",
    "- Enfin, on stocke séparément un entier correspondant au chiffre manuscrit (on appelle ça le \"label\", ou étiquette, de l'image).\n",
    "\n",
    "Ce faisant, on obtient donc deux tableaux: \n",
    "- `images` possède $60000$ lignes (soit $10$ chiffres zéro, un, $\\hdots$ dessinés par $6000$ personnes) et $784=28^2$  colonnes (images de $28\\times 28$ pixels stockées sous formes de vecteurs). `images[i]` correspond alors à la $i$ème image, représentée par un vecteur de $\\Rsp^{768}$.\n",
    "- `labels` possède $60000$ lignes et une seule colonne: `label[i]` contient le numéro du chiffre manuscrit représenté par l'image `images[i]`\n",
    "\n",
    "La fonction `read_mnist()` ci-dessous télécharge ces données et retourne les tableaux `images` et `labels`. On fournit une fonction d'affichage: `show_mnist(images[i])` affiche la $i$ème image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import du jeu de données MNIST de Yan Lecun: 60000 chiffres manuscrits avec labels\n",
    "import os\n",
    "import struct\n",
    "import urllib\n",
    "import gzip\n",
    "import shutil\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "def gunzip(iname,oname):\n",
    "    with gzip.open(iname, 'rb') as f_in:\n",
    "        with open(oname, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "def download_mnist(dest):\n",
    "    src = 'http://yann.lecun.com/exdb/mnist'\n",
    "    for f in ['train-images-idx3-ubyte', 'train-labels-idx1-ubyte']:\n",
    "        urlretrieve('%s/%s.gz' % (src,f), '%s/%s.gz' % (dest,f))\n",
    "        gunzip('%s/%s.gz' % (dest,f),'%s/%s' % (dest,f))\n",
    "def read_mnist():\n",
    "    d = os.path.expanduser('~/.m315-mnist-data')\n",
    "    if not os.path.isdir(d):\n",
    "        os.makedirs(d)\n",
    "        download_mnist(d)\n",
    "    with open('%s/train-labels-idx1-ubyte' % d, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        labels = np.fromfile(flbl, dtype=np.int8)\n",
    "    with open('%s/train-images-idx3-ubyte' % d, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        images = np.fromfile(fimg, dtype=np.uint8).reshape(len(labels), rows*cols)/255.\n",
    "    return images,labels\n",
    "def show_mnist(image, cmap='gray'):\n",
    "    plt.figure()\n",
    "    imgplot = plt.imshow(np.reshape(image,(28,-1)), interpolation='nearest', cmap=cmap)\n",
    "   \n",
    "images,labels = read_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**QIV.0** Passer quelques minutes à jouer avec les fonctions show_mnist() et print() (afficher les labels, et aussi les vecteurs images[i]) pour comprendre le jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(28, 28)\n",
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff25ea2f7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# exemple d'image: faire varier un peu i pour comprendre le jeu de données\n",
    "i = 16\n",
    "x = images[i]\n",
    "p = np.reshape(images[i],(28,28))\n",
    "show_mnist(p)\n",
    "print(x.shape)\n",
    "print(p.shape)\n",
    "print(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**QIV.1** Construire un tableau `X0` contenant $m=100$ images du chiffre zéro extraite du tableau `images`, et un tableau `X1` contenant également $m$ représentants du chiffre un également extraits de `images` (`X0` et `X1` possèderont donc $n=2m$ lignes et $784$ colonnes). Construire ensuite les données du problème d'optimisation:\n",
    "- Un tableau `X` de $n=2m$ lignes et $784$ colonnes obtenu en mettant à bout `X0` et `X1` (on pourra utiliser np.vstack). \n",
    "- Un tableau `A0` (resp. `A1`) contenant la liste des indices correspondant aux chiffres zéro (resp un)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# <completer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**QIV.2** Résoudre le problème d'optimisation $\\min_{w\\in\\Rsp^d} F(w)$ pour $\\gamma=0.1$ en utilisant la méthode de Newton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# <completer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Étant donné $w^* \\in \\Rsp^{768}$ l'unique solution du problème d'optimisation, on notera $u^*: x\\mapsto\\sigma(\\sca{x}{w^*})$. Le principe de la régression logistique (cf intro du TD) est que  $u^*(x_a) \\simeq 1$ si $a \\in A_0$ (c'est-à-dire si l'image $x_a$ représente le chiffre zéro) et $u^*(x_a) \\simeq 0$ si $a\\in A_1$ (si l'image $x_a$ représente le chiffre un). Comme on a utilisé seulement une petite fraction des images pour construire $w$ (on a choisi $n=100$ images du chiffre zéro alors que la base de données en contient $6000$!), on va maintenant chercher à valider la méthode en comparant la catégorie ($0$ où $1$) devinée par la fonction $u^*$ à celle enregistrée dans le tableau `labels` sur l'ensemble des zéros et des uns manuscrits contenus dans la base de données.\n",
    "\n",
    "**QIV.3** Vérifier la pertinence de la méthode de la manière suivante :\n",
    "- Pour chaque image MNIST $x = images[i]$ représentant un $0$ où un $1$ (pour tout $i$ tel que labels[i] $\\in \\{0,1\\}$), calculer $u^*(x)$, et définir `label_devine`=0 si $u(x)< 1/2$ et `label_devine`=$1$ sinon.\n",
    "- Comparer  label_devine au véritables label (i.e. `labels[i]`).\n",
    "- Calculer enfin la proportion de cas où `label_devine=labels[i]`: ce nombre mesure la proportion de cas où la régression logistique permet de reconnaître correctement le chiffre représenté par l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# <completer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**QIV.4:** Afficher le vecteur $w$ sous la forme d'une image en utilisant show_mnist(). Interpréter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# <completer>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**QIV.5** Adapter l'approche à la séparation des chiffres 0 de tout les autres chiffres. (on pourra prendre m=100 chiffres $0$ et $m$ chiffres de chaque autre classe, soit 1000 points de donnée au total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# <completer>\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
